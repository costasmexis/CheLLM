{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adf1a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c218c6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 28 passages from the PDF.\n",
      "First 3 passages: ['Dr.', 'Kokossis, FIChemE, FIEE, FRSA, and FIET, is Professor of Process Systems Engineering \\nat the National Technical University of Athens.', 'He is a Chartered Engineer with IChemE \\n(UK).']\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(path):\n",
    "    doc = fitz.open(path)\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "    return full_text\n",
    "\n",
    "def split_into_passages(text, chunk_size=10):\n",
    "    sentences = text.split(\". \")\n",
    "    passages = []\n",
    "    chunk = \"\"\n",
    "    for sentence in sentences:\n",
    "        if len(chunk) + len(sentence) < chunk_size:\n",
    "            chunk += sentence + \". \"\n",
    "        else:\n",
    "            passages.append(chunk.strip())\n",
    "            chunk = sentence + \". \"\n",
    "    if chunk:\n",
    "        passages.append(chunk.strip())\n",
    "    return passages\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"./data/document.pdf\")\n",
    "documents = split_into_passages(pdf_text)\n",
    "print(f'Extracted {len(documents)} passages from the PDF.')\n",
    "print(f'First 3 passages: {documents[:3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9cff3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electrical engineer\n"
     ]
    }
   ],
   "source": [
    "# 2. Load embedding model and encode documents\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")  # much better than raw BERT\n",
    "document_embeddings = embedder.encode(documents)\n",
    "\n",
    "# 3. Create FAISS index\n",
    "dimension = document_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(document_embeddings))\n",
    "\n",
    "# 4. Define your query and embed it\n",
    "query = \"Is Konstantinos an electrical engineer or a chemical engineer?\"\n",
    "query_embedding = embedder.encode([query])\n",
    "\n",
    "# 5. Search for top relevant docs\n",
    "top_k = 1\n",
    "distances, indices = index.search(np.array(query_embedding), top_k)\n",
    "retrieved_texts = [documents[i] for i in indices[0]]\n",
    "\n",
    "# 6. Use a local language model to generate the answer\n",
    "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
    "input_text = f\"Context: {retrieved_texts[0]} \\n\\nQuestion: {query}\"\n",
    "result = generator(input_text)\n",
    "\n",
    "print(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bacdfe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
